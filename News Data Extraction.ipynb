{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to find all articles from a set of websites by keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Websites currently included:\n",
    "\n",
    "* CNN.com\n",
    "\n",
    "* Bloomberg.com\n",
    "\n",
    "* BBC.com\n",
    "\n",
    "* Euronews.com\n",
    "\n",
    "* RT.com\n",
    "\n",
    "* CNBC.com\n",
    "\n",
    "* France24.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: \n",
    "Instead of Google Searches try scraping webarchive if the XPATH keeps changing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Webscrape\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "from googlesearch import search\n",
    "\n",
    "# Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# newspaper\n",
    "import newspaper as news\n",
    "# RSS\n",
    "import feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keywords(string):\n",
    "    '''\n",
    "    Takes an input string of comma separated keywords and\n",
    "    parses it into a list\n",
    "    \n",
    "    (string) -> (list of strings)\n",
    "    '''\n",
    "    keywords = string.split(\",\")\n",
    "    return keywords\n",
    "\n",
    "class website:\n",
    "    '''\n",
    "    The website class, contains the link to the search site, \n",
    "    and some parameters for performing the search on it.\n",
    "    '''\n",
    "    def __init__(self, link):\n",
    "        '''\n",
    "        Website constructor, requires a link (string) to the screen which supports searching, \n",
    "        preferably just the search page if it exists.\n",
    "        (string) -> (website)\n",
    "        '''\n",
    "        self.address = link\n",
    "        self.newspaper = news.build(link)\n",
    "        \n",
    "\n",
    "def search_website(keywords, website):\n",
    "    '''\n",
    "    Takes in a list of keywords from make_keywords, and a website name in the list of websites,\n",
    "    \n",
    "    Returns a data frame of variables about each article\n",
    "    (list, website) -> (data frame)\n",
    "    '''\n",
    "    driver.get(website.address) # move the driver to the website address\n",
    "    time.wait(20) # wait for 20 seconds for the website to load\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newspaper Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_news = news.build(\"http://cnn.com\")\n",
    "print(50*\"*\")\n",
    "print(\"Length:\")\n",
    "print(50*\"*\")\n",
    "CNN_news.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bloomberg_news = news.build(\"https://www.bloomberg.com\")\n",
    "print(50*\"*\")\n",
    "print(\"Length:\")\n",
    "print(50*\"*\")\n",
    "Bloomberg_news.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bloomberg_news.size())\n",
    "print(50*\"*\")\n",
    "print(\"Titles:\")\n",
    "for article in Bloomberg_news.articles:\n",
    "    print(article.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSS Feeds Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_world_news = feedparser.parse(\"http://rss.cnn.com/rss/cnn_world.rss\")\n",
    "CNN_money_top_news = feedparser.parse(\"http://rss.cnn.com/rss/money_topstories.rss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_world_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(50*\"*\")\n",
    "print(\"Titles:\")\n",
    "print(50*\"*\")\n",
    "i = 0\n",
    "while i < len(CNN_world_news[\"entries\"]):\n",
    "    print(CNN_world_news[\"entries\"][i][\"title\"])\n",
    "    i=i+1\n",
    "i = 0 \n",
    "print(50*\"*\")\n",
    "print(\"Titles:\")\n",
    "print(50*\"*\")\n",
    "while i < len(CNN_money_top_news[\"entries\"]):\n",
    "    print(CNN_money_top_news[\"entries\"][i][\"title\"])\n",
    "    i=i+1\n",
    "print(50*\"*\")\n",
    "print(\"Structure:\")\n",
    "print(50*\"*\")\n",
    "print(CNN_money_top_news[\"entries\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Webscraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Browser:\n",
    "\n",
    "    def __init__(self, initiate=True, implicit_wait_time = 10, explicit_wait_time = 2):\n",
    "        self.implicit_wait_time = implicit_wait_time    # http://www.aptuz.com/blog/selenium-implicit-vs-explicit-waits/\n",
    "        self.explicit_wait_time = explicit_wait_time    # http://www.aptuz.com/blog/selenium-implicit-vs-explicit-waits/\n",
    "        if initiate:\n",
    "            self.start()\n",
    "        return\n",
    "\n",
    "    def start(self):\n",
    "        self.driver = webdriver.Chrome(\"/Users/michalmalyska/Programming/chromedriver\")\n",
    "        self.driver.implicitly_wait(self.implicit_wait_time)\n",
    "        return\n",
    "\n",
    "    def end(self):\n",
    "        self.driver.quit()\n",
    "        return\n",
    "\n",
    "    def go_to_url(self, url, wait_time = None):\n",
    "        if wait_time is None:\n",
    "            wait_time = self.explicit_wait_time\n",
    "        self.driver.get(url)\n",
    "        print('[*] Fetching results from: {}'.format(url))\n",
    "        time.sleep(wait_time)\n",
    "        return\n",
    "\n",
    "    def get_search_url(self, query, page_num=0, per_page=100, lang='en'):\n",
    "        query = quote_plus(query)\n",
    "        url = 'https://www.google.hr/search?q={}&num={}&start={}&nl={}'.format(query, per_page, page_num*per_page, lang)\n",
    "        return url\n",
    "\n",
    "    def scrape(self, n):\n",
    "        #xpath migth change in future\n",
    "        i = 1\n",
    "        links = []\n",
    "        while i < n:\n",
    "            links.append(self.driver.find_elements_by_xpath(\"//*[@id='rso']/div/div/div[\" + str(i) + \"]/div/div/div[1]/span/div/div/ol/li/a\")) # searches for all links insede h3 tags with class \"r\"\n",
    "            i += 1\n",
    "            # //*[@id=\"rso\"]/div/div/div[1]/div/div/div[1]/span/div/div/ol/li/a\n",
    "            # //*[@id=\"rso\"]/div/div/div[2]/div/div/div[1]/span/div/div/ol/li/a\n",
    "        results = []\n",
    "        i = 1\n",
    "        for link in links:\n",
    "            print(\"Loop Number\", i)\n",
    "            print(\"Link\", link)\n",
    "            try:\n",
    "                print(\"Try 1\")\n",
    "                d = {'url': link[0].get_attribute('href')}\n",
    "                results.append(d)\n",
    "                print(d)\n",
    "            except Exception as e:\n",
    "                print(\"Exception 1\")\n",
    "                print(e)\n",
    "            i += 1\n",
    "                \n",
    "        return results\n",
    "\n",
    "    def search(self, query, page_num=0, per_page=10, lang='en', wait_time = None, n = 2):\n",
    "        if wait_time is None:\n",
    "            wait_time = self.explicit_wait_time\n",
    "        url = self.get_search_url(query, page_num, per_page, lang)\n",
    "        self.go_to_url(url, wait_time)\n",
    "        results = self.scrape(n)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate the browser\n",
    "browser = Browser()\n",
    "# Let it sleep for 10 seconds to make sure it loads properly\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to google.ca\n",
    "browser.go_to_url(\"https://www.google.ca/\")\n",
    "\n",
    "# Temporary keyword, can be later passed in a loop or sth\n",
    "keyword = \"Deloitte\"\n",
    "# We can restrict this to just certain sites by the parameter:\n",
    "# site:<url address>\n",
    "# (CNN example)\n",
    "site = \"bloomberg.com\"\n",
    "\n",
    "#elem = browser.find_element_by_name(\"q\")  # Find the search box\n",
    "#elem.send_keys(\"site:\" + site + \" \" + keyword + Keys.RETURN) # Type in the stuff into the search box\n",
    "\n",
    "query = \"site:\" + site + \" \" + keyword\n",
    "# Or we can use the class above:\n",
    "results = browser.search(query, per_page = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"Deloitte\"\n",
    "site = \"bloomberg.com/news/articles\"\n",
    "query = \"site:\" + site + \" \" + keyword\n",
    "\n",
    "for term in browser.search(query):\n",
    "    browser.go_to_url(term[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_bloomberg(keywords, n, debug = False):\n",
    "    '''\n",
    "    (list) -> (data frame)\n",
    "    Performs a search on bloomberg.com for news about the keyword.\n",
    "    Returns a dataframe with:\n",
    "    \n",
    "    keyword | link | author | headline | date | website | # likes | #shares | # views | language\n",
    "    \n",
    "    '''\n",
    "    # Add one to n to make it have expected behaviour\n",
    "    n = n + 1\n",
    "    \n",
    "    # Start the search browser (for the class Browser defined above)\n",
    "    browser = Browser()\n",
    "    \n",
    "    # Start another web browser (regular web driver)\n",
    "    driver = webdriver.Chrome(\"/Users/michalmalyska/Programming/chromedriver\")\n",
    "    \n",
    "    main = pd.DataFrame(\n",
    "        {\n",
    "            \"keyword\" : [],\n",
    "            \"link\" : [],\n",
    "            \"author\" : [],\n",
    "            \"headline\" : [],\n",
    "            \"Topic\" : [],\n",
    "            \"date\" : [],\n",
    "            \"website\" : [],\n",
    "            \"likes\" : [],\n",
    "            \"shares\" : [],\n",
    "            \"views\" : [],\n",
    "            \"language\" :[]\n",
    "        })\n",
    "    for keyword in keywords:\n",
    "        # initialize the dataframe\n",
    "        df = pd.DataFrame(\n",
    "        {\n",
    "            \"keyword\" : [],\n",
    "            \"link\" : [],\n",
    "            \"author\" : [],\n",
    "            \"headline\" : [],\n",
    "            \"Topic\" : [],\n",
    "            \"date\" : [],\n",
    "            \"website\" : [],\n",
    "            \"likes\" : [],\n",
    "            \"shares\" : [],\n",
    "            \"views\" : [],\n",
    "            \"language\" :[]\n",
    "        })\n",
    "        site = \"bloomberg.com/news\"\n",
    "        query = \"site:\" + site + \" \" + keyword\n",
    "        for term in browser.search(query, n = n):\n",
    "            \n",
    "            if debug:\n",
    "                print(term)\n",
    "            \n",
    "            # Go to the url\n",
    "            driver.get(term[\"url\"])\n",
    "            \n",
    "            # /html/body/main/div/article/div[2]/div/div/address/div/a\n",
    "            # Author xpath\n",
    "            #Author1 = driver.find_element_by_xpath(\"/html/body/main/div/article/div[2]/div/div/address/div/a\")\n",
    "            # Currently does not work, element.text is an empty string, so I will resort to using classes.\n",
    "            \n",
    "            \n",
    "            # class : author-v2__byline\n",
    "            try:\n",
    "                Author = driver.find_element_by_class_name(\"author-v2__byline\").text\n",
    "            except:\n",
    "                try:\n",
    "                    Author = driver.find_element_by_class_name(\"author\").text\n",
    "                except: \n",
    "                    Author = \"NA\"\n",
    "            \n",
    "            # /html/body/main/div/article/div[2]/div/div/div[2]/time\n",
    "            # Date xpath\n",
    "            # Date = driver.find_element_by_xpath(\"/html/body/main/div/article/div[2]/div/div/div[2]/time\")\n",
    "            \n",
    "            # class : article-timestamp\n",
    "            try:\n",
    "                Date = driver.find_element_by_class_name(\"article-timestamp\").text\n",
    "            except:\n",
    "                Date = \"NA\"\n",
    "            # /html/body/main/div/article/div[2]/div/div/h1\n",
    "            # Headline \n",
    "            # Headline = driver.find_element_by_xpath(\"/html/body/main/div/article/div[2]/div/div/h1\")\n",
    "            \n",
    "            # class: lede-text-v2__hed\n",
    "            try: \n",
    "                Headline = driver.find_element_by_class_name(\"lede-text-v2__hed\").text\n",
    "            except:\n",
    "                try:\n",
    "                    Headline = driver.find_element_by_class_name(\"lede-text-only__highlight\").text\n",
    "                except:\n",
    "                    Headline = \"NA\"\n",
    "            \n",
    "            # class eyebrow-v2\n",
    "            try:\n",
    "                Topic = driver.find_element_by_class_name(\"eyebrow-v2\").text\n",
    "            except:\n",
    "                try: \n",
    "                    Topic = driver.find_element_by_class_name(\"eyebrow\").text\n",
    "                except: \n",
    "                    Topic = \"NA\"\n",
    "            # Shares Likes and Views unavailable\n",
    "            Shares = -1\n",
    "            Likes = -1\n",
    "            Views = -1\n",
    "            \n",
    "            # Language fixed to english\n",
    "            Language = \"ENG\"\n",
    "            \n",
    "            # Keyword\n",
    "            Keyword = keyword\n",
    "            \n",
    "            # Link\n",
    "            Link = term[\"url\"]\n",
    "            \n",
    "            # Website \n",
    "            Website = \"Bloomberg\"\n",
    "            \n",
    "            df2 = pd.DataFrame(\n",
    "            {\n",
    "            \"keyword\" : [Keyword],\n",
    "            \"link\" : [Link],\n",
    "            \"author\" : [Author],\n",
    "            \"headline\" : [Headline],\n",
    "            \"Topic\" : [Topic],\n",
    "            \"date\" : [Date],\n",
    "            \"website\" : [Website],\n",
    "            \"likes\" : [Likes],\n",
    "            \"shares\" : [Shares],\n",
    "            \"views\" : [Views],\n",
    "            \"language\" :[Language]\n",
    "            })\n",
    "            \n",
    "            df = df.append(df2)\n",
    "        main = main.append(df)\n",
    "    return(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Fetching results from: https://www.google.hr/search?q=site%3Abloomberg.com%2Fnews+Deloitte+AI&num=10&start=0&nl=en\n",
      "Loop Number 1\n",
      "Link [<selenium.webdriver.remote.webelement.WebElement (session=\"b4976ea0bbf92ce21d0f7dc2ed9ae73f\", element=\"0.8907667958497989-1\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"b4976ea0bbf92ce21d0f7dc2ed9ae73f\", element=\"0.8907667958497989-2\")>]\n",
      "Try 1\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:zBoGrZ3o0m8J:https://www.bloomberg.com/news/articles/2018-12-12/artificial-intelligence-has-some-explaining-to-do+&cd=1&hl=en&ct=clnk&gl=ca'}\n",
      "Loop Number 2\n",
      "Link [<selenium.webdriver.remote.webelement.WebElement (session=\"b4976ea0bbf92ce21d0f7dc2ed9ae73f\", element=\"0.8907667958497989-3\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"b4976ea0bbf92ce21d0f7dc2ed9ae73f\", element=\"0.8907667958497989-4\")>]\n",
      "Try 1\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:YM6cb-9e4ckJ:https://www.bloomberg.com/news/articles/2018-08-15/ai-to-reshape-finance-say-executives-who-struggle-to-define-it+&cd=2&hl=en&ct=clnk&gl=ca'}\n",
      "Loop Number 3\n",
      "Link [<selenium.webdriver.remote.webelement.WebElement (session=\"b4976ea0bbf92ce21d0f7dc2ed9ae73f\", element=\"0.8907667958497989-5\")>]\n",
      "Try 1\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:XM9RNXpOMsUJ:https://www.bloomberg.com/news/articles/2017-09-25/deloitte-email-platform-and-client-data-accessed-by-cyberattack+&cd=8&hl=en&ct=clnk&gl=ca'}\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:zBoGrZ3o0m8J:https://www.bloomberg.com/news/articles/2018-12-12/artificial-intelligence-has-some-explaining-to-do+&cd=1&hl=en&ct=clnk&gl=ca'}\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:YM6cb-9e4ckJ:https://www.bloomberg.com/news/articles/2018-08-15/ai-to-reshape-finance-say-executives-who-struggle-to-define-it+&cd=2&hl=en&ct=clnk&gl=ca'}\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:XM9RNXpOMsUJ:https://www.bloomberg.com/news/articles/2017-09-25/deloitte-email-platform-and-client-data-accessed-by-cyberattack+&cd=8&hl=en&ct=clnk&gl=ca'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>headline</th>\n",
       "      <th>Topic</th>\n",
       "      <th>date</th>\n",
       "      <th>website</th>\n",
       "      <th>likes</th>\n",
       "      <th>shares</th>\n",
       "      <th>views</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deloitte AI</td>\n",
       "      <td>https://webcache.googleusercontent.com/search?...</td>\n",
       "      <td>Jeremy Kahn</td>\n",
       "      <td>Artificial Intelligence Has Some Explaining to Do</td>\n",
       "      <td></td>\n",
       "      <td>December 12, 2018, 6:00 AM EST</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deloitte AI</td>\n",
       "      <td>https://webcache.googleusercontent.com/search?...</td>\n",
       "      <td>Emma Kinery</td>\n",
       "      <td>AI to Reshape Finance, Say Executives Who Stru...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>August 15, 2018, 6:00 PM EDT</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deloitte AI</td>\n",
       "      <td>https://webcache.googleusercontent.com/search?...</td>\n",
       "      <td>Giles Turner</td>\n",
       "      <td>Deloitte Email Platform and Client Data Hit by...</td>\n",
       "      <td>Technology</td>\n",
       "      <td>September 25, 2017, 10:38 AM EDT</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword                                               link  \\\n",
       "0  Deloitte AI  https://webcache.googleusercontent.com/search?...   \n",
       "0  Deloitte AI  https://webcache.googleusercontent.com/search?...   \n",
       "0  Deloitte AI  https://webcache.googleusercontent.com/search?...   \n",
       "\n",
       "         author                                           headline  \\\n",
       "0   Jeremy Kahn  Artificial Intelligence Has Some Explaining to Do   \n",
       "0   Emma Kinery  AI to Reshape Finance, Say Executives Who Stru...   \n",
       "0  Giles Turner  Deloitte Email Platform and Client Data Hit by...   \n",
       "\n",
       "        Topic                              date    website  likes  shares  \\\n",
       "0                December 12, 2018, 6:00 AM EST  Bloomberg   -1.0    -1.0   \n",
       "0  Technology      August 15, 2018, 6:00 PM EDT  Bloomberg   -1.0    -1.0   \n",
       "0  Technology  September 25, 2017, 10:38 AM EDT  Bloomberg   -1.0    -1.0   \n",
       "\n",
       "   views language  \n",
       "0   -1.0      ENG  \n",
       "0   -1.0      ENG  \n",
       "0   -1.0      ENG  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_bloomberg(keywords=[\"Deloitte AI\"], n = 3, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_CNN(keywords, n, debug = False):\n",
    "    '''\n",
    "    (list) -> (data frame)\n",
    "    Performs a search on CNN.com for news about the keyword.\n",
    "    Returns a dataframe with:\n",
    "    \n",
    "    keyword | link | author | headline | date | website | # likes | #shares | # views | language\n",
    "    \n",
    "    '''\n",
    "    # Add one to n to make it have expected behaviour\n",
    "    n = n + 1\n",
    "    \n",
    "    # Start the search browser (for the class Browser defined above)\n",
    "    browser = Browser()\n",
    "    \n",
    "    # Start another web browser (regular web driver)\n",
    "    driver = webdriver.Chrome(\"/Users/michalmalyska/Programming/chromedriver\")\n",
    "    \n",
    "    main = pd.DataFrame(\n",
    "        {\n",
    "            \"keyword\" : [],\n",
    "            \"link\" : [],\n",
    "            \"author\" : [],\n",
    "            \"headline\" : [],\n",
    "            \"Topic\" : [],\n",
    "            \"date\" : [],\n",
    "            \"website\" : [],\n",
    "            \"likes\" : [],\n",
    "            \"shares\" : [],\n",
    "            \"views\" : [],\n",
    "            \"language\" :[]\n",
    "        })\n",
    "    for keyword in keywords:\n",
    "        # initialize the dataframe\n",
    "        df = pd.DataFrame(\n",
    "        {\n",
    "            \"keyword\" : [],\n",
    "            \"link\" : [],\n",
    "            \"author\" : [],\n",
    "            \"headline\" : [],\n",
    "            \"Topic\" : [],\n",
    "            \"date\" : [],\n",
    "            \"website\" : [],\n",
    "            \"likes\" : [],\n",
    "            \"shares\" : [],\n",
    "            \"views\" : [],\n",
    "            \"language\" :[]\n",
    "        })\n",
    "        site = \"cnn.com\"\n",
    "        query = \"site:\" + site + \" \" + keyword\n",
    "        for term in browser.search(query, n = n):\n",
    "            \n",
    "            if debug:\n",
    "                print(term)\n",
    "            \n",
    "            # Go to the url\n",
    "            driver.get(term[\"url\"])\n",
    "            \n",
    "            # /html/body/main/div/article/div[2]/div/div/address/div/a\n",
    "            # Author xpath\n",
    "            #Author1 = driver.find_element_by_xpath(\"/html/body/main/div/article/div[2]/div/div/address/div/a\")\n",
    "            # Currently does not work, element.text is an empty string, so I will resort to using classes.\n",
    "            \n",
    "            \n",
    "            # class : author-v2__byline\n",
    "            try:\n",
    "                Author = driver.find_element_by_class_name(\"metadata__byline__author\").text\n",
    "            except:\n",
    "                try:\n",
    "                    Author = driver.find_element_by_class_name(\"author\").text\n",
    "                except: \n",
    "                    try: \n",
    "                        Author = driver.find_element_by_class_name(\"bold author-name\").text\n",
    "                    except:\n",
    "                        Author = \"NA\"\n",
    "            \n",
    "            # /html/body/main/div/article/div[2]/div/div/div[2]/time\n",
    "            # Date xpath\n",
    "            # Date = driver.find_element_by_xpath(\"/html/body/main/div/article/div[2]/div/div/div[2]/time\")\n",
    "            \n",
    "            # class : article-timestamp\n",
    "            try:\n",
    "                Date = driver.find_element_by_class_name(\"update-time\").text\n",
    "            except:\n",
    "                try: \n",
    "                    Date = driver.find_element_by_class_name(\"timestamp published-date padding-12-left\").text\n",
    "                except:\n",
    "                    Date = \"NA\"\n",
    "            # /html/body/main/div/article/div[2]/div/div/h1\n",
    "            # Headline \n",
    "            # Headline = driver.find_element_by_xpath(\"/html/body/main/div/article/div[2]/div/div/h1\")\n",
    "            \n",
    "            # class: lede-text-v2__hed\n",
    "            try: \n",
    "                Headline = driver.find_element_by_class_name(\"article-headline_articleHeadlineContainer__qoLpy_885427b2\").text\n",
    "            except:\n",
    "                try:\n",
    "                    Headline = driver.find_element_by_class_name(\"heading-content\").text\n",
    "                except:\n",
    "                    Headline = \"NA\"\n",
    "            \n",
    "            # class eyebrow-v2\n",
    "            try:\n",
    "                Topic = driver.find_element_by_class_name(\"eyebrow-v2\").text\n",
    "            except:\n",
    "                try: \n",
    "                    Topic = driver.find_element_by_class_name(\"eyebrow\").text\n",
    "                except: \n",
    "                    Topic = \"NA\"\n",
    "            # Shares Likes and Views unavailable\n",
    "            Shares = -1\n",
    "            Likes = -1\n",
    "            Views = -1\n",
    "            \n",
    "            # Language fixed to english\n",
    "            Language = \"ENG\"\n",
    "            \n",
    "            # Keyword\n",
    "            Keyword = keyword\n",
    "            \n",
    "            # Link\n",
    "            Link = term[\"url\"]\n",
    "            \n",
    "            # Website \n",
    "            Website = \"CNN\"\n",
    "            \n",
    "            df2 = pd.DataFrame(\n",
    "            {\n",
    "            \"keyword\" : [Keyword],\n",
    "            \"link\" : [Link],\n",
    "            \"author\" : [Author],\n",
    "            \"headline\" : [Headline],\n",
    "            \"Topic\" : [Topic],\n",
    "            \"date\" : [Date],\n",
    "            \"website\" : [Website],\n",
    "            \"likes\" : [Likes],\n",
    "            \"shares\" : [Shares],\n",
    "            \"views\" : [Views],\n",
    "            \"language\" :[Language]\n",
    "            })\n",
    "            \n",
    "            df = df.append(df2)\n",
    "        main = main.append(df)\n",
    "    return(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Fetching results from: https://www.google.hr/search?q=site%3Acnn.com+Deloitte+AI&num=10&start=0&nl=en\n",
      "Loop Number 1\n",
      "Link [<selenium.webdriver.remote.webelement.WebElement (session=\"21e8f39f7fe13e630b71771509e08bd3\", element=\"0.1860618389828277-1\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"21e8f39f7fe13e630b71771509e08bd3\", element=\"0.1860618389828277-2\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"21e8f39f7fe13e630b71771509e08bd3\", element=\"0.1860618389828277-3\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"21e8f39f7fe13e630b71771509e08bd3\", element=\"0.1860618389828277-4\")>]\n",
      "Try 1\n",
      "{'url': 'http://webcache.googleusercontent.com/search?q=cache:s5vL7lJ6aDMJ:tech.fortune.cnn.com/2016/12/22/robots-jobs-ai/+&cd=4&hl=en&ct=clnk&gl=ca'}\n",
      "Loop Number 2\n",
      "Link [<selenium.webdriver.remote.webelement.WebElement (session=\"21e8f39f7fe13e630b71771509e08bd3\", element=\"0.1860618389828277-5\")>]\n",
      "Try 1\n",
      "{'url': 'http://webcache.googleusercontent.com/search?q=cache:sZ8_6hrhB8YJ:tech.fortune.cnn.com/2017/07/22/augmented-reality-corporate-training/+&cd=15&hl=en&ct=clnk&gl=ca'}\n",
      "Loop Number 3\n",
      "Link [<selenium.webdriver.remote.webelement.WebElement (session=\"21e8f39f7fe13e630b71771509e08bd3\", element=\"0.1860618389828277-6\")>]\n",
      "Try 1\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:0Qyj6PrCBKUJ:https://money.cnn.com/gallery/pf/jobs/2014/06/17/top-mba-employers/15.html+&cd=6&hl=en&ct=clnk&gl=ca'}\n",
      "{'url': 'http://webcache.googleusercontent.com/search?q=cache:s5vL7lJ6aDMJ:tech.fortune.cnn.com/2016/12/22/robots-jobs-ai/+&cd=4&hl=en&ct=clnk&gl=ca'}\n",
      "{'url': 'http://webcache.googleusercontent.com/search?q=cache:sZ8_6hrhB8YJ:tech.fortune.cnn.com/2017/07/22/augmented-reality-corporate-training/+&cd=15&hl=en&ct=clnk&gl=ca'}\n",
      "{'url': 'https://webcache.googleusercontent.com/search?q=cache:0Qyj6PrCBKUJ:https://money.cnn.com/gallery/pf/jobs/2014/06/17/top-mba-employers/15.html+&cd=6&hl=en&ct=clnk&gl=ca'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>headline</th>\n",
       "      <th>Topic</th>\n",
       "      <th>date</th>\n",
       "      <th>website</th>\n",
       "      <th>likes</th>\n",
       "      <th>shares</th>\n",
       "      <th>views</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deloitte AI</td>\n",
       "      <td>http://webcache.googleusercontent.com/search?q...</td>\n",
       "      <td>By REUTERS December 22, 2016</td>\n",
       "      <td>Why You Shouldn’t Worry About Robots Stealing ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deloitte AI</td>\n",
       "      <td>http://webcache.googleusercontent.com/search?q...</td>\n",
       "      <td>By JAY SAMIT July 22, 2017</td>\n",
       "      <td>4 Ways Augmented Reality Could Change Corporat...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deloitte AI</td>\n",
       "      <td>https://webcache.googleusercontent.com/search?...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>CNN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       keyword                                               link  \\\n",
       "0  Deloitte AI  http://webcache.googleusercontent.com/search?q...   \n",
       "0  Deloitte AI  http://webcache.googleusercontent.com/search?q...   \n",
       "0  Deloitte AI  https://webcache.googleusercontent.com/search?...   \n",
       "\n",
       "                         author  \\\n",
       "0  By REUTERS December 22, 2016   \n",
       "0    By JAY SAMIT July 22, 2017   \n",
       "0                            NA   \n",
       "\n",
       "                                            headline Topic date website  \\\n",
       "0  Why You Shouldn’t Worry About Robots Stealing ...    NA   NA     CNN   \n",
       "0  4 Ways Augmented Reality Could Change Corporat...    NA   NA     CNN   \n",
       "0                                                 NA    NA   NA     CNN   \n",
       "\n",
       "   likes  shares  views language  \n",
       "0   -1.0    -1.0   -1.0      ENG  \n",
       "0   -1.0    -1.0   -1.0      ENG  \n",
       "0   -1.0    -1.0   -1.0      ENG  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_CNN(keywords=[\"Deloitte AI\"], n = 3, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"/Users/michalmalyska/Programming/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://webcache.googleusercontent.com/search?q=cache:s5vL7lJ6aDMJ:tech.fortune.cnn.com/2016/12/22/robots-jobs-ai/+&cd=4&hl=en&ct=clnk&gl=ca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"class name\",\"selector\":\"metadata__byline__author\"}\n  (Session info: chrome=71.0.3578.98)\n  (Driver info: chromedriver=2.44.609545 (c2f88692e98ce7233d2df7c724465ecacfe74df5),platform=Mac OS X 10.14.1 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-0df9c92370e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"metadata__byline__author\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_class_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \"\"\"\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"class name\",\"selector\":\"metadata__byline__author\"}\n  (Session info: chrome=71.0.3578.98)\n  (Driver info: chromedriver=2.44.609545 (c2f88692e98ce7233d2df7c724465ecacfe74df5),platform=Mac OS X 10.14.1 x86_64)\n"
     ]
    }
   ],
   "source": [
    "driver.find_element_by_class_name(\"metadata__byline__author\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why You Shouldn’t Worry About Robots Stealing Your Jobs'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.find_element_by_class_name(\"heading-content\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
